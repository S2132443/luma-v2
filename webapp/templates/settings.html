{% extends "base.html" %}

{% block title %}Settings - Luma Bot{% endblock %}

{% block content %}
<h1>Settings</h1>

{% if success %}
<div class="success-message">
    Settings saved successfully! The bot will use the new personality immediately.
</div>
{% endif %}

<form method="post">
    <label for="model_provider">Model Provider:</label>
    <select id="model_provider" name="model_provider">
        <option value="deepseek" {% if model_provider == 'deepseek' %}selected{% endif %}>DeepSeek API</option>
        <option value="ollama" {% if model_provider == 'ollama' %}selected{% endif %}>Ollama (Local)</option>
    </select>

    <div id="deepseek_section" style="display: {% if model_provider == 'deepseek' %}block{% else %}none{% endif %};">
        <label for="deepseek_api_key">DeepSeek API Key:</label>
        <input type="password" id="deepseek_api_key" name="deepseek_api_key" value="{{ deepseek_key }}" placeholder="sk-...">
    </div>

    <div id="ollama_section" style="display: {% if model_provider == 'ollama' %}block{% else %}none{% endif %};">
        <label for="ollama_endpoint">Ollama Endpoint:</label>
        <input type="text" id="ollama_endpoint" name="ollama_endpoint" value="{{ ollama_endpoint }}" placeholder="http://localhost:11434" onchange="fetchOllamaModels()">

        <label for="ollama_model">Ollama Model:</label>
        <select id="ollama_model" name="ollama_model">
            <option value="{{ ollama_model }}">{{ ollama_model if ollama_model else 'Select a model...' }}</option>
        </select>
        <button type="button" onclick="fetchOllamaModels()">Refresh Models</button>
    </div>

    <label for="discord_token">Discord Token:</label>
    <input type="password" id="discord_token" name="discord_token" value="{{ discord_token }}" placeholder="Your Discord bot token">

    <label for="personality">Bot Personality:</label>
    <textarea id="personality" name="personality" placeholder="Define how your bot should behave...">{{ personality }}</textarea>

    <label for="memory_suggestions_enabled">AI Memory Suggestions:</label>
    <select id="memory_suggestions_enabled" name="memory_suggestions_enabled">
        <option value="false" {% if memory_suggestions_enabled == 'false' or memory_suggestions_enabled == False %}selected{% endif %}>Disabled (Default)</option>
        <option value="true" {% if memory_suggestions_enabled == 'true' %}selected{% endif %}>Enabled</option>
    </select>

    <input type="submit" value="Save Settings">
</form>

<script>
// Function to handle provider change
function handleProviderChange() {
    const providerSelect = document.getElementById('model_provider');
    const deepseekSection = document.getElementById('deepseek_section');
    const ollamaSection = document.getElementById('ollama_section');

    if (providerSelect.value === 'deepseek') {
        deepseekSection.style.display = 'block';
        ollamaSection.style.display = 'none';
    } else if (providerSelect.value === 'ollama') {
        deepseekSection.style.display = 'none';
        ollamaSection.style.display = 'block';
        // Fetch models when switching to Ollama
        setTimeout(fetchOllamaModels, 100); // Small delay to ensure UI update
    }
}

// Initial setup when page loads
document.addEventListener('DOMContentLoaded', function() {
    // Set up the provider change event listener
    document.getElementById('model_provider').addEventListener('change', handleProviderChange);

    // Initialize the correct section based on current selection
    handleProviderChange();
});

function fetchOllamaModels() {
    const endpoint = document.getElementById('ollama_endpoint').value || 'http://ollama:11434';
    const modelSelect = document.getElementById('ollama_model');

    if (!modelSelect) return; // Exit if element doesn't exist

    // Show loading state
    modelSelect.innerHTML = '<option value="">Loading...</option>';

    fetch('/api/ollama_models')
        .then(response => response.json())
        .then(data => {
            if (!modelSelect) return; // Check again after async operation

            modelSelect.innerHTML = ''; // Clear the loading option

            if (data.models && data.models.length > 0) {
                // Add fetched models
                data.models.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model;
                    option.textContent = model;
                    modelSelect.appendChild(option);
                });
            } else {
                // If no models found, show a default option
                const option = document.createElement('option');
                option.value = '';
                option.textContent = 'No models found';
                modelSelect.appendChild(option);
            }
        })
        .catch(error => {
            console.error('Error fetching Ollama models:', error);
            if (modelSelect) {
                modelSelect.innerHTML = '<option value="">Error loading models</option>';
            }
        });
}
</script>
{% endblock %}